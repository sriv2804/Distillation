# Distillation
#Response Based Knowledge Distillation
resnet 18 is used as teacher model

resnet 8 and resnet20 are used as student models

resnet18--Trainable params: 11,173,962

resnet20--Trainable params: 283,754

resnet08--Trainable params: 89,322

|                        | **Paper** | **Implementation** |
|------------------------|-----------|--------------------|
| **Resnet18**           | 95.26     | 95.27              |
| **Resnet8_baseline**   | 89.59     | Not tested         |
| **Resnet8_distilled**  | 89.50     | 89.71              |
| **Resnet20_baseline**  | 93.02     | 92.6               |
| **Resnet20_distilled** | Not done  | 93.45              |                                                       


